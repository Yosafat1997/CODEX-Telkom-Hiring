# -*- coding: utf-8 -*-
"""CODEX.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Rd9svATqJdfoh8zYrOIZ6alk5a3zUkIB
"""

!pip install pandas
!pip install numpy
import pandas as pd
import numpy as np
from google.colab import drive
import datetime
import math
import time
drive.mount('/content/gdrive')
from dateutil.relativedelta import relativedelta

"""### 1. Add dataset ###"""

dataset = pd.read_csv("/content/gdrive/MyDrive/dataset HR analytics.csv")

dataset

percent_missing = dataset.isnull().sum() * 100 / len(dataset)
missing_value_df = pd.DataFrame({'column_name': dataset.columns,
                                 'percent_missing': percent_missing})

missing_value_df

"""Convert both DateofHire and DateofTermination. Set to now if not terminate"""

dataset['DateofHire'] = pd.to_datetime(dataset['DateofHire'])
dataset['DateofTermination'] = pd.to_datetime(dataset['DateofTermination'])
dataset['DateofTermination']= dataset['DateofTermination'].fillna(pd.Timestamp('now'))

dataset['Working_Duration'] = (dataset['DateofTermination'] - dataset['DateofHire']).astype('<m8[Y]')

dataset['LastPerformanceReview_Date'] = pd.to_datetime(dataset['LastPerformanceReview_Date'])
dataset['HiringtoReviewTime'] = (dataset['LastPerformanceReview_Date'] - dataset['DateofHire']).astype('<m8[Y]')

dataset

"""Get Average of EngagementSurvey,EmpSatisfaction and Absences from each tribe,squad and role"""

engagement=dataset[['Tribe','Squad','RoleID','EngagementSurvey']]
satisfaction=dataset[['Tribe','Squad','RoleID','EmpSatisfaction']]
ws=dataset[['Tribe','Squad','RoleID','Working_Duration']]

engagement_tribe=engagement.groupby('Tribe').mean().rename(columns={'EngagementSurvey':'EngagementSurvey_tribe'})
engagement_squad=engagement.groupby('Squad').mean().rename(columns={'EngagementSurvey':'EngagementSurvey_squad'})
engagement_role=engagement.groupby('RoleID').mean().rename(columns={'EngagementSurvey':'EngagementSurvey_role'})
satisf_tribe=satisfaction.groupby('Tribe').mean().rename(columns={'EmpSatisfaction':'EmpSatisfaction_tribe'})
satisf_squad=satisfaction.groupby('Squad').mean().rename(columns={'EmpSatisfaction':'EmpSatisfaction_squad'})
satisf_role=satisfaction.groupby('RoleID').mean().rename(columns={'EmpSatisfaction':'EmpSatisfaction_role'})
service_tribe=ws.groupby('Tribe').mean().rename(columns={'Working_Duration':'Working_Duration_tribe'})
service_squad=ws.groupby('Squad').mean().rename(columns={'Working_Duration':'Working_Duration_squad'})
service_role=ws.groupby('RoleID').mean().rename(columns={'Working_Duration':'Working_Duration_role'})
tribe = pd.merge(engagement_tribe,satisf_tribe[['EmpSatisfaction_tribe']],on='Tribe')
tribe = pd.merge(tribe,service_tribe[['Working_Duration_tribe']],on='Tribe')
squad = pd.merge(engagement_squad ,satisf_squad[['EmpSatisfaction_squad']],on='Squad')
squad  = pd.merge(squad,service_squad[['Working_Duration_squad']],on='Squad')
role = pd.merge(engagement_role ,satisf_role[['EmpSatisfaction_role']],on='RoleID')
role  = pd.merge(role,service_role[['Working_Duration_role']],on='RoleID')

squad

dataset = pd.merge(dataset,squad[['EngagementSurvey_squad','EmpSatisfaction_squad','Working_Duration_squad']],on='Squad')
dataset = pd.merge(dataset,role[['EngagementSurvey_role','EmpSatisfaction_role','Working_Duration_role']],on='RoleID')
dataset = pd.merge(dataset,tribe[['EngagementSurvey_tribe','EmpSatisfaction_tribe','Working_Duration_tribe']],on='Tribe')

dataset

dataset['Engagement_Squad_Deviation'] = dataset['EngagementSurvey']-dataset['EngagementSurvey_squad']
dataset['Engagement_Role_Deviation'] = dataset['EngagementSurvey']-dataset['EngagementSurvey_role']
dataset['Engagement_Tribe_Deviation'] = dataset['EngagementSurvey']-dataset['EngagementSurvey_tribe']
dataset['Satisfaction_Squad_Deviation'] = dataset['EmpSatisfaction']-dataset['EmpSatisfaction_squad']
dataset['Satisfaction_Role_Deviation'] = dataset['EmpSatisfaction']-dataset['EmpSatisfaction_role']
dataset['Satisfaction_Tribe_Deviation'] = dataset['EmpSatisfaction']-dataset['EmpSatisfaction_tribe']
dataset['Service_Squad_Deviation'] = dataset['Working_Duration']-dataset['Working_Duration_squad']
dataset['Service_Role_Deviation'] = dataset['Working_Duration']-dataset['Working_Duration_role']
dataset['Service_Tribe_Deviation'] = dataset['Working_Duration']-dataset['Working_Duration_tribe']

dataset

"""create class for our target (if termination date is null set 0 else 1), named as "is Terminate""""

def termination_class(row):
  if row['EmploymentStatus'] == 'Active' : return 0
  else:
    return 1

dataset['IsTerminate'] = dataset.apply(lambda row: termination_class(row), axis=1)

"""convert all categorical data to numerical"""

cols = ['MarriedID','MaritalStatusID','GenderID','EmpStatusID','RoleID','LevelID','PerfScoreID','Tribe','Squad','TermReason','EmploymentStatus','RecruitmentSource','RaceDesc']
for w in cols:
   dataset[w] = dataset[w].astype("category").cat.codes

dataset

list(dataset.columns)

selected = dataset[[
 'MarriedID',
 'MaritalStatusID',
 'GenderID',
 'RoleID',
 'LevelID',
 'PerfScoreID',
 'Tribe',
 'Squad',
 'RecruitmentSource',
 'EngagementSurvey',
 'EmpSatisfaction',
 'SpecialProjectsCount',
 'DaysLateLast30',
 'RaceDesc',
 'Absences',
 'Working_Duration',
 'Engagement_Squad_Deviation',
 'Engagement_Role_Deviation',
 'Engagement_Tribe_Deviation',
 'Satisfaction_Squad_Deviation',
 'Satisfaction_Role_Deviation',
 'Satisfaction_Tribe_Deviation',
 'Service_Squad_Deviation',
 'Service_Role_Deviation',
 'Service_Tribe_Deviation',
 'IsTerminate']]

class_balanced = selected[['IsTerminate','PerfScoreID']]

class_balanced.groupby('IsTerminate').count()

"""### 3. Using sklearn decision tree here. Evaluation done using cross validation method. Stratified k-fold with k = 10 in used since data are pretty big in size ###"""

!pip install sklearn
!pip install pingouin
from sklearn.model_selection import StratifiedKFold
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_validate
import pingouin as pg

strat_kfold = StratifiedKFold(n_splits=10)

model = DecisionTreeClassifier(criterion='entropy')

termination_outcome=selected.pop('IsTerminate').values
feature=selected.values

scores = cross_validate(model, feature, termination_outcome,cv=10, scoring=['accuracy','precision','recall','roc_auc'])

sorted(scores.keys())

scores

print('10-Fold Result: \nAccuracy: {}\nPrecission: {}\nRecall: {}\nROC-AUC: {}'
.format(np.mean(scores['test_accuracy']),np.mean(scores['test_precision']),np.mean(scores['test_recall']),np.mean(scores['test_roc_auc'])))
